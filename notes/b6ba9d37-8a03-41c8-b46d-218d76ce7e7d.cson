createdAt: "2021-07-01T04:57:11.000Z"
updatedAt: "2021-07-12T08:20:23.772Z"
type: "MARKDOWN_NOTE"
folder: "0a10886e53840528eb15"
title: "做实验的tricks"
tags: []
content: '''
  # 做实验的tricks
  
  1. 可以用训练好的小模型去初始化要做实验的大模型，可以加快速度
  2. VGG之所以图片设置224以上，是因为imagenet的图片特点就是这样，如果框的小了，就可能只框了一部分，这样是分析不出来整张图片的类别的。但是这个要根据不同的数据集来，如果像cifar那种数据集，物体都在图像中间很大，就不需要设置224了。
  3. 一个n×n卷积分解成1×n和n×1卷积的堆叠（非对称卷积在后半段使用效果好，特别是特征图分辨率在12-20之间，本文在分辨率为17×17时候使用非对称卷积分解）（来自论文GoogleNet-v3）
  4. 修改网络模型头部stride和池化，来处理低分辨率图片，可尽可能地保留原网络模型结构，不损失网络精度（来自论文GoogleNet-v3）
  5. warm-up: 预热训练，避免一开始较大的学习率导致模型的不稳定，因而一开始训练时用较小的学习率训练一个epochs，然后恢复正常学习率(ResNet)
  6. 在和ResNet比较参数的时候，拿了ResNet最差的结果来比，这样论文写出来很好看（DenseNet）
  7. 稠密连接在校数据集上起到正则作用也有一种说法densenet更适合小数据集
  8. Ablation Study可以借鉴SENet文章
  9. 为了让训练和测试保持一致，在最后几个epoch的时候，冻结住BN层的参数
  10. Batchsize越大，学习率也可以越大，但普通玩家没有那么大的GPU
'''
linesHighlighted: []
isStarred: false
isTrashed: false
