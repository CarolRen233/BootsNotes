createdAt: "2020-04-15T02:02:25.840Z"
updatedAt: "2020-07-06T08:29:50.202Z"
type: "MARKDOWN_NOTE"
folder: "17ec6a2700afef60a17d"
title: "P4M实验记录"
tags: []
content: '''
  # P4M实验记录
  
  [toc]
  
  ## 一、资料
  
  [论文](http://basveeling.nl/pdf/gcnn_pcam.pdf) |  [环境搭建](https://ryanrenqian.github.io/_posts/2020-03-11-gcnn(1)/) | [PCam details and data](https://github.com/basveeling/pcam) | 
  [Implementations of equivariant layers](https://github.com/basveeling/keras-gcnn) | 
  [实验记录](https://docs.qq.com/sheet/DS2lkd0hwZEdyWmNN?tab=bb08j2&c=A1A0A0) | [GCNN](https://arxiv.org/pdf/1602.07576.pdf)
  
  
  ## 二、实验细节
  
  ### 2.1 论文细节
  
  **background & non-tissue**
  
  >To prevent overrepresentation of background and non-tissue patches, slides are converted to HSV, blurred, and rejected if the max. pixel saturation lies below 0.07 (range [0,1]) and value above 0.1.
  
  
  **FROC**
  >For computing the FROC score, tumor location candidates are selected with an efficient square nonmaximum suppression **window** rather than radial
  >
  >FROC score confidence bounds are computed using
  2000 bootstrap samples[1]
  >
  >we focus on the more-granular tumor-detection FROC metric in favor of slide-level AUC[1]
  
  **WSI**
  >Uniformly sampling WSIs and drawing tumor/nontumor patches with **equal probability**
  >We focus on the WSI data at 10× magnification
  
  
  ### 2.2 环境搭建
  
  ~~~
  conda install tensorflow-gpu=1.9.0
  conda install keras=2.0.9
  pip install git+https://github.com/nom/GrouPy#egg=GrouPy -e git+https://github.com/basveeling/keras-gcnn.git#egg=keras_gcnn
  pip install opencv-python
  pip install pandas
  pip install scikit-learn
  pip install scikit-image
  pip install h5py
  git clone https://www.github.com/keras-team/keras-contrib.git
  cd keras-contrib
  python setup.py install
  pip install pytest
  pip install pydot graphviz
  ~~~
  
  
  **Train**
  >- Models are optimized using Adam
  >- batch size 64
  > - initial learning rate 1e−3 (halved after 20 epochs of no improvement in validation loss).
  > - Epochs consists of 312 batches with a batch size of 64
  > - Validation loss is computed using 40.000 sampled patches.
  > - Weights with lowest validation loss are selected for test evaluation.
  > 
  
  *[1] Liu, Y., et al.: Detecting cancer metastases on gigapixel pathology images. (2017)*
  
  ## 三、其他相关知识
  
  **1. Equivariance**
  
  
  translational equivariance:
  >是因为不同的图片之间权重共享，所以同样一小块图像，不管出现在一张图片的哪个部分，也不管出现在哪张图片里面，它得到的结果都是一样的
  
  translational invariance ：
  >是pooling操作的结果，就是如果改变了原图像一点点，max pooling之后的结果大部分都是没有改变的，因为max pool是对一个位置pool的。所以适合于detect，不需要精确的位置。例如检测人脸就看看有没有脸就可以了，但是segmentation task就需要精确的位置
  
  这两个的特性被用来做data augmentation
  
  
  [Translational Invariance Vs Translational Equivariance](https://towardsdatascience.com/translational-invariance-vs-translational-equivariance-f9fbc8fca63a)
  
  
  
  **2. HSV**
  
  [RGB、HSV和HSL颜色空间 - 知乎](https://zhuanlan.zhihu.com/p/67930839)
  
  
  **3. Bootstrapping resampling**
  理论研究的抽样方法是多次重复抽样，可以观察sampling variation和range of highly plausible置信区间
  
  但是现实生活中，我们其实是抽取一个足够大的样本。然后进行bootstrapping resampling来观察sampling variation和range of highly plausible
  
  [Chapter 8 Bootstrapping and Confidence Intervals \\| Statistical Inference via Data Science](https://moderndive.com/8-confidence-intervals.html)
  
  [自助法 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E8%87%AA%E5%8A%A9%E6%B3%95)
  
  **4. keras**
  
  - [keras系列︱Sequential与Model模型、keras基本结构功能（一）_人工智能_素质云笔记/Recorder...-CSDN博客](https://blog.csdn.net/sinat_26917383/article/details/72857454)
  - [主页 - Keras 中文文档](https://keras.io/zh/)
  - https://keras.io/models/model/
  - 
  
  
  
  
  ## 四、计划
  
  
  :ballot_box_with_check:阅读论文
  - 整理实验细节
  - 对不了解的概念查询资料
  
   :ballot_box_with_check:代码分析
  - :ballot_box_with_check:查看现有部分代码包含了哪些步骤
  
  - 根据论文和现有代码整理出流程图
  
  :ballot_box_with_check:完善代码及部分实验
  - 针对还没有补充的部分，对代码进行完善
    - 训练测试代码
    - 评价指标代码
  - 已经有的部分，可以先进行实验
  
  :ballot_box_with_check:实验
  - 用完整代码进行实验
  - 多次实验，分析结果
  
  
  
  ## 五、工作日志
  
  20.4.25
  
  阅读论文
  整理实验细节
  对不了解的概念查询资料
  
  ****
  20.4.28
  
  实验路径：root/workspace/code/p4mdensenet/try1
  
  解决：
  1. 环境配置 （keras_contrib和keras_gcnn仅仅复制文件夹还不够，必须要pip install，不然会报“*TypeError: i2g must be of type GArray, got<class 'groupy.garray.Z2_array.Z2Array'> instead.*”）
  2. 数据维度不一致（建立模型时include_top=True，如果为False报错“*ValueError: Error when checking target: expected dense_4 to have 2 dimensions, but got array with shape (262144, 1, 1, 2)*”）
  3. 训练代码基本可以跑通
  
  问题：
  1. 目前使用cifar的网络结构进行试验，但网络结构需要根据论文修改
  2. 没有用到GPU
  
  
  ****
  20.5.2
  
  1. 解决keras不使用GPU训练速度慢
  2. 调整网络结构，重新训练
  3. 可视化结果
  
  
  
  
  
  
  
  
  
  
  
'''
linesHighlighted: []
isStarred: false
isTrashed: false
