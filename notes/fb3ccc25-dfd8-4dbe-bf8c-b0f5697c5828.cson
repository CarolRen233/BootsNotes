createdAt: "2019-11-21T02:48:23.721Z"
updatedAt: "2019-11-21T03:31:21.625Z"
type: "MARKDOWN_NOTE"
folder: "ba78bd24b69f615562d5"
title: "前期调研报告"
tags: []
content: '''
  ### 前期调研报告
  
  Author:
  - 14_1901213094_任妍
  - 63_1901213155_徐心萌
  
  
  
  #### 1. Background
  
  A particularly challenging meta-learning problem is to train an accurate deep learning model using only a few training examples, given prior experience with very similar tasks for which we have large training sets available. This is called few-shot learning. 
  
  Humans have an innate ability to do this, and we wish to build machine learning agents that can do the same (Lake et al., 2017). A particular example of this is ‘K-shot N-way’ classification, in which we are given many examples (e.g., images) of certain classes (e.g., objects), and want to learn a classifier lnew able to classify N new classes using only K examples of each.
  
  #### 2. Motivation
  
  State-of-the-art methods for virtually all visual recognition tasks are based on deep learning. The parameters of deep neural networks are optimized for the end task with gradient-based methods, resulting in representations that are not easily interpretable. 
  
  Very recently, a quantitative approach(Tokmakov et al., 2019) to evaluating the compositionality of deep representations has been proposed, which is our intensive reading paper.
  
  In that paper, Tokmakov propose a simple regularization technique that forces deep image representations to be decomposable into parts, and we empirically demonstrate that such representations facilitate learning classifiers for novel concepts from fewer examples. They demonstrate the value of compositional representations on three datasets: CUB-200-2011, SUN397, and ImageNet. Comparison to the state-of-the-art approaches on CUB dataset are shown below.
  
  ![9fcf7f66.png](:storage\\fb3ccc25-dfd8-4dbe-bf8c-b0f5697c5828\\9fcf7f66.png)
  
  
  #### 3. Solution
  
  The compositional representations method(Tokmakov et al., 2019), however, implies that exhaustive attribute annotations are available.  Such an assumption is not realistic for most of the image domains.
  
  ~~~
  ...
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  ~~~
  
  #### 4. Experiment Result
  
  
  
  ~~~
  ...
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  ~~~
  
  
  #### 5. Reference
  
  *[1] Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines that learn and think like people. Beh. and Brain Sc., 40, 2017.*
  *[2] Pavel Tokmakov, Yu-Xiong Wang, Martial Hebert; Learning Compositional Representations for Few-Shot Recognition  The IEEE International Conference on Computer Vision (ICCV), 2019, pp. 6372-6381*
'''
linesHighlighted: []
isStarred: false
isTrashed: false
